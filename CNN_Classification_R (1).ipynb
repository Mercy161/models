{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    },
    "language_info": {
      "name": "R"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install necessary packages\n",
        "install.packages(\"keras\")\n",
        "install.packages(\"tensorflow\")\n",
        "install.packages(\"caret\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxQepSDUv6W9",
        "outputId": "6e803b95-12b8-4687-f353-06d236c94ded"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load libraries\n",
        "library(keras)\n",
        "library(tensorflow)\n",
        "library(caret)"
      ],
      "metadata": {
        "id": "FRuqbSLgv_TV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load your data\n",
        "data <- read.csv(\"/content/SNVpcadata112.csv\")\n",
        "\n",
        "# Check data structure and summary\n",
        "str(data)\n",
        "summary(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        },
        "id": "JlpzzcZEwCAq",
        "outputId": "29d90ff7-0506-4c85-845f-5677c3f928e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'data.frame':\t1320 obs. of  11 variables:\n",
            " $ Groups: num  12.3 12.3 12.3 12.3 12.3 ...\n",
            " $ PC1   : num  18.5 24.4 31.4 39.9 46.7 ...\n",
            " $ PC2   : num  1.35 2.65 1.16 1.11 5.65 ...\n",
            " $ PC3   : num  3.44 7.22 6.58 12.37 1.54 ...\n",
            " $ PC4   : num  -13.5 -10.6 -13.4 -21.7 -10.9 ...\n",
            " $ PC5   : num  8.04 8.37 7.77 14.5 3.52 ...\n",
            " $ PC6   : num  -1.806 0.274 -2.26 -2.244 -1.771 ...\n",
            " $ PC7   : num  1.141 3.471 1.756 -1.606 0.907 ...\n",
            " $ PC8   : num  -3.35 -6.01 -6.61 -6.49 -1.26 ...\n",
            " $ PC9   : num  1.027 1.262 -0.259 0.295 5.716 ...\n",
            " $ PC10  : num  -2.897 -1.512 0.104 -1.378 3.248 ...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "     Groups           PC1                PC2                PC3          \n",
              " Min.   :10.58   Min.   :-60.3872   Min.   :-42.3482   Min.   :-28.8526  \n",
              " 1st Qu.:12.32   1st Qu.:-17.6568   1st Qu.: -8.6752   1st Qu.: -5.8679  \n",
              " Median :21.30   Median : -0.6547   Median :  0.5938   Median : -0.4768  \n",
              " Mean   :20.28   Mean   :  0.0000   Mean   :  0.0000   Mean   :  0.0000  \n",
              " 3rd Qu.:25.55   3rd Qu.: 16.1322   3rd Qu.:  8.7328   3rd Qu.:  5.5009  \n",
              " Max.   :29.40   Max.   : 74.5124   Max.   : 31.7772   Max.   : 26.8101  \n",
              "      PC4                PC5                 PC6                PC7          \n",
              " Min.   :-23.8401   Min.   :-24.47765   Min.   :-27.4505   Min.   :-23.1754  \n",
              " 1st Qu.: -4.7322   1st Qu.: -4.77663   1st Qu.: -2.8807   1st Qu.: -3.6055  \n",
              " Median :  0.9969   Median :  0.03676   Median :  0.8984   Median :  0.2349  \n",
              " Mean   :  0.0000   Mean   :  0.00000   Mean   :  0.0000   Mean   :  0.0000  \n",
              " 3rd Qu.:  5.9040   3rd Qu.:  5.18415   3rd Qu.:  4.2291   3rd Qu.:  3.5689  \n",
              " Max.   : 22.1306   Max.   : 21.65781   Max.   : 16.5529   Max.   : 29.1165  \n",
              "      PC8                  PC9                PC10         \n",
              " Min.   :-23.842458   Min.   :-17.4129   Min.   :-16.6810  \n",
              " 1st Qu.: -3.355637   1st Qu.: -3.7622   1st Qu.: -2.9944  \n",
              " Median :  0.005164   Median :  0.2846   Median :  0.4269  \n",
              " Mean   :  0.000000   Mean   :  0.0000   Mean   :  0.0000  \n",
              " 3rd Qu.:  3.712556   3rd Qu.:  4.2005   3rd Qu.:  3.4419  \n",
              " Max.   : 29.053998   Max.   : 14.9851   Max.   : 15.0230  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert target variable to binary (0/1) format\n",
        "data$Group <- as.factor(data$Group)\n",
        "target <- as.numeric(data$Group) - 1  # Convert to binary 0/1\n",
        "\n",
        "# Normalize the features\n",
        "features <- scale(data[, -which(names(data) == \"Group\")])  # Exclude the 'Group' column which is the target"
      ],
      "metadata": {
        "id": "Fn80IJtRwGQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "set.seed(123)\n",
        "index <- sample(1:nrow(features), 0.8 * nrow(features))\n",
        "train_features <- features[index, ]\n",
        "train_target <- target[index]\n",
        "test_features <- features[-index, ]\n",
        "test_target <- target[-index]\n"
      ],
      "metadata": {
        "id": "qX2oqLTvwKbn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape the data for CNN input (add a dimension for the channel)\n",
        "train_features <- array_reshape(train_features, c(nrow(train_features), ncol(train_features), 1))\n",
        "test_features <- array_reshape(test_features, c(nrow(test_features), ncol(test_features), 1))\n"
      ],
      "metadata": {
        "id": "6ooFfSFQwQH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E5JSrQZSzYkf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "model <- keras_model_sequential() %>%\n",
        "  layer_conv_1d(filters = 64, kernel_size = 3, activation = 'relu',\n",
        "                input_shape = c(ncol(train_features), 1),\n",
        "                kernel_regularizer = regularizer_l2(l = 0.02), # Pass l = regularization factor\n",
        "                padding = 'same') %>%\n",
        "  layer_max_pooling_1d(pool_size = 2) %>%\n",
        "  layer_dropout(rate = 0.3) %>%\n",
        "  layer_conv_1d(filters = 128, kernel_size = 3, activation = 'relu',\n",
        "                kernel_regularizer = regularizer_l2(l = 0.02), # Pass l = regularization factor\n",
        "                padding = 'same') %>%\n",
        "  layer_max_pooling_1d(pool_size = 2) %>%\n",
        "  layer_dropout(rate = 0.3) %>%\n",
        "  layer_flatten() %>%\n",
        "  layer_dense(units = 64, activation = 'relu',\n",
        "              kernel_regularizer = regularizer_l2(l = 0.02)) %>% # Pass l = regularization factor\n",
        "  layer_dropout(rate = 0.3) %>%\n",
        "  layer_dense(units = 1, activation = 'sigmoid')  # Change to binary classification output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "id": "p60Xx0VSy6uM",
        "outputId": "ccd2dd49-2db1-4809-c07e-f29716d176d2",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ERROR",
          "evalue": "L2.__init__() got an unexpected keyword argument 'l'",
          "traceback": [
            "L2.__init__() got an unexpected keyword argument 'l'Traceback:\n",
            "1. keras_model_sequential() %>% layer_conv_1d(filters = 64, kernel_size = 3, \n .     activation = \"relu\", input_shape = c(ncol(train_features), \n .         1), kernel_regularizer = regularizer_l2(l = 0.02), padding = \"same\") %>% \n .     layer_max_pooling_1d(pool_size = 2) %>% layer_dropout(rate = 0.3) %>% \n .     layer_conv_1d(filters = 128, kernel_size = 3, activation = \"relu\", \n .         kernel_regularizer = regularizer_l2(l = 0.02), padding = \"same\") %>% \n .     layer_max_pooling_1d(pool_size = 2) %>% layer_dropout(rate = 0.3) %>% \n .     layer_flatten() %>% layer_dense(units = 64, activation = \"relu\", \n .     kernel_regularizer = regularizer_l2(l = 0.02)) %>% layer_dropout(rate = 0.3) %>% \n .     layer_dense(units = 1, activation = \"sigmoid\")",
            "2. layer_dense(., units = 1, activation = \"sigmoid\")",
            "3. create_layer(keras$layers$Dense, object, list(units = as.integer(units), \n .     activation = activation, use_bias = use_bias, kernel_initializer = kernel_initializer, \n .     bias_initializer = bias_initializer, kernel_regularizer = kernel_regularizer, \n .     bias_regularizer = bias_regularizer, activity_regularizer = activity_regularizer, \n .     kernel_constraint = kernel_constraint, bias_constraint = bias_constraint, \n .     input_shape = normalize_shape(input_shape), batch_input_shape = normalize_shape(batch_input_shape), \n .     batch_size = as_nullable_integer(batch_size), dtype = dtype, \n .     name = name, trainable = trainable, weights = weights))",
            "4. layer_dropout(., rate = 0.3)",
            "5. create_layer(keras$layers$Dropout, object, list(rate = rate, \n .     noise_shape = normalize_shape(noise_shape), seed = seed, \n .     input_shape = normalize_shape(input_shape), batch_input_shape = normalize_shape(batch_input_shape), \n .     batch_size = as_nullable_integer(batch_size), name = name, \n .     trainable = trainable, weights = weights))",
            "6. layer_dense(., units = 64, activation = \"relu\", kernel_regularizer = regularizer_l2(l = 0.02))",
            "7. create_layer(keras$layers$Dense, object, list(units = as.integer(units), \n .     activation = activation, use_bias = use_bias, kernel_initializer = kernel_initializer, \n .     bias_initializer = bias_initializer, kernel_regularizer = kernel_regularizer, \n .     bias_regularizer = bias_regularizer, activity_regularizer = activity_regularizer, \n .     kernel_constraint = kernel_constraint, bias_constraint = bias_constraint, \n .     input_shape = normalize_shape(input_shape), batch_input_shape = normalize_shape(batch_input_shape), \n .     batch_size = as_nullable_integer(batch_size), dtype = dtype, \n .     name = name, trainable = trainable, weights = weights))",
            "8. regularizer_l2(l = 0.02)",
            "9. keras$regularizers$l2(l = l)",
            "10. py_call_impl(callable, call_args$unnamed, call_args$named)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model %>% compile(\n",
        "  loss = 'binary_crossentropy',  # Use binary cross-entropy for binary classification\n",
        "  optimizer = optimizer_adam(learning_rate = 0.001),\n",
        "  metrics = 'accuracy'\n",
        ")\n",
        "# Print the model summary\n",
        "model %>% summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "Li6b-AM7wasY",
        "outputId": "f745afe2-8861-4240-8d4c-c1cb16c5ea38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ERROR",
          "evalue": "Error in eval(expr, envir, enclos): object 'model' not found\n",
          "traceback": [
            "Error in eval(expr, envir, enclos): object 'model' not found\nTraceback:\n",
            "1. model %>% compile(loss = \"binary_crossentropy\", optimizer = optimizer_adam(learning_rate = 0.001), \n .     metrics = \"accuracy\")",
            "2. compile(., loss = \"binary_crossentropy\", optimizer = optimizer_adam(learning_rate = 0.001), \n .     metrics = \"accuracy\")"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Early Stopping callback\n",
        "early_stopping <- callback_early_stopping(\n",
        "  monitor = \"val_loss\",\n",
        "  patience = 100,\n",
        "  restore_best_weights = TRUE\n",
        ")\n"
      ],
      "metadata": {
        "id": "e_Yv_BkVwpxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model with validation data and Early Stopping\n",
        "history <- model %>% fit(\n",
        "  x = train_features,\n",
        "  y = train_target,\n",
        "  validation_split = 0.2,\n",
        "  epochs = 1500,\n",
        "  batch_size = 64,\n",
        "  callbacks = list(early_stopping)\n",
        ")"
      ],
      "metadata": {
        "id": "i4WD3KHBwwwA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on test data\n",
        "evaluation <- model %>% evaluate(test_features, test_target)\n",
        "cat(\"Test loss:\", evaluation[[1]], \"\\n\")\n",
        "cat(\"Test accuracy:\", evaluation[[2]], \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ObOTvSyw1sT",
        "outputId": "6cb0323b-3d58-4e5f-e91f-066196519fc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.3030628 \n",
            "Test accuracy: 0.924812 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the test set\n",
        "test_predictions <- model %>% predict(test_features)\n",
        "test_predictions_classes <- ifelse(test_predictions > 0.5, 1, 0)  # Convert probabilities to binary classes\n"
      ],
      "metadata": {
        "id": "6szjouESw6RG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure the predictions and target have the same length\n",
        "stopifnot(length(test_predictions_classes) == length(test_target))\n",
        "\n",
        "# Convert to factor for caret\n",
        "test_target_factor <- as.factor(test_target)\n",
        "test_predictions_classes_factor <- as.factor(test_predictions_classes)"
      ],
      "metadata": {
        "id": "omSN1JNOw93n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate confusion matrix using caret\n",
        "conf_matrix <- confusionMatrix(test_predictions_classes_factor, test_target_factor)\n",
        "\n",
        "# Print confusion matrix\n",
        "print(conf_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEqV4_nFxE_v",
        "outputId": "87ac817a-9907-4d96-920b-b0b5529a8cd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix and Statistics\n",
            "\n",
            "          Reference\n",
            "Prediction  0  1\n",
            "         0 27  2\n",
            "         1  8 96\n",
            "                                          \n",
            "               Accuracy : 0.9248          \n",
            "                 95% CI : (0.8661, 0.9634)\n",
            "    No Information Rate : 0.7368          \n",
            "    P-Value [Acc > NIR] : 3.349e-08       \n",
            "                                          \n",
            "                  Kappa : 0.7948          \n",
            "                                          \n",
            " Mcnemar's Test P-Value : 0.1138          \n",
            "                                          \n",
            "            Sensitivity : 0.7714          \n",
            "            Specificity : 0.9796          \n",
            "         Pos Pred Value : 0.9310          \n",
            "         Neg Pred Value : 0.9231          \n",
            "             Prevalence : 0.2632          \n",
            "         Detection Rate : 0.2030          \n",
            "   Detection Prevalence : 0.2180          \n",
            "      Balanced Accuracy : 0.8755          \n",
            "                                          \n",
            "       'Positive' Class : 0               \n",
            "                                          \n"
          ]
        }
      ]
    }
  ]
}